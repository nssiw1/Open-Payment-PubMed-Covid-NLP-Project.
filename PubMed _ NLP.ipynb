{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "tqdm.monitor_interval = 0\n",
    "from Bio import Entrez, Medline\n",
    "Entrez.email = 'Ricky.Li@apothecom.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '(COVID-19 OR SARS-CoV-2 OR Corona virus OR Coronavirus) AND (\"2020/03/15\"[PDat]:\"2020/03/24\"[PDat]) AND English[lang]))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(COVID-19 OR SARS-CoV-2 OR Corona virus OR Coronavirus) AND (\"2020/03/15\"[PDat]:\"2020/03/24\"[PDat]) AND English[lang])) - 648 result(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['PMID', 'OWN', 'STAT', 'LR', 'IS', 'DP', 'TI', 'LID', 'AB', 'CI', 'FAU',\n",
       "       'AU', 'AD', 'LA', 'PT', 'DEP', 'PL', 'TA', 'JT', 'JID', 'PMC', 'OTO',\n",
       "       'OT', 'EDAT', 'MHDA', 'CRDT', 'PHST', 'AID', 'PST', 'SO', 'VI', 'IP',\n",
       "       'PG', 'COIS', 'SB', 'DCOM', 'TT', 'RN', 'MH', 'AUID', 'GR', 'CN', 'EIN',\n",
       "       'CON', 'CIN', 'UOF', 'EFR', 'IR', 'FIR', 'PMCR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle = Entrez.esearch(db='pubmed', retmax=99999, term=query, rettype='xml')\n",
    "record = Entrez.read(handle)\n",
    "id_list = list(record['IdList'])\n",
    "master_id_list = id_list\n",
    "print(query + ' - ' + str(len(id_list)) + ' result(s).')\n",
    "\n",
    "# Fetch full search result from PubMed\n",
    "def FetchFullResults(idlist):\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\")\n",
    "    records = Medline.parse(handle)\n",
    "    records_list = list(records)\n",
    "    return records_list\n",
    "\n",
    "full_records = FetchFullResults(master_id_list)\n",
    "df_full_records = pd.DataFrame(full_records)\n",
    "df_full_records.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 648/648 [00:00<00:00, 833.78it/s]\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(columns=['PMID', 'Title', 'All Authors', 'Abstract', 'Journal', 'Publication Type', 'Publication Year', 'Full Citation', 'PubMed Link'])\n",
    "data['PMID'] = master_id_list\n",
    "\n",
    "# go through the master id list and collect information\n",
    "for i in tqdm(range(len(data['PMID']))):\n",
    "    \n",
    "    if df_full_records['FAU'][i] is not np.nan:\n",
    "        author_list = df_full_records['FAU'][i]\n",
    "        # return all authors in a string separated by \",\"\n",
    "        authors = '; '.join(author_list)\n",
    "    else:\n",
    "        first_author, authors, authors_ama = None, None, None\n",
    "        \n",
    "    #  Title and Abstract body\n",
    "    abstract = df_full_records['AB'][i]\n",
    "    if abstract is np.nan:\n",
    "        abstract = ''\n",
    "    title = df_full_records['TI'][i]\n",
    "    if title is np.nan:\n",
    "        title = ''\n",
    "         \n",
    "    \n",
    "    journal = df_full_records['TA'][i]\n",
    "    \n",
    "    # Full citation \n",
    "    try:\n",
    "        cit_chunks = df_full_records['SO'][i].split('.')\n",
    "        if df_full_records['PST'][i] == 'aheadofprint':\n",
    "            cit_no_journal = cit_chunks[1] + '. [Epub ahead of print]' \n",
    "            full_cit = cit_chunks[0] + '.' +cit_chunks[1] + '. [Epub ahead of print]'\n",
    "        else:\n",
    "            cit_no_journal = cit_chunks[1] + '.'\n",
    "            full_cit = cit_chunks[0] + '.' + cit_chunks[1] + '.'\n",
    "    except AttributeError:\n",
    "        cit_no_journal = journal\n",
    "        full_cit = journal\n",
    "        \n",
    "    # Publication type    \n",
    "    try:   \n",
    "        publication_type = '\\n'.join(df_full_records['PT'][i])\n",
    "    except TypeError:\n",
    "        publication_type = ''\n",
    "        \n",
    "    # Publication Year\n",
    "    publication_year = df_full_records['DP'][i].split(' ')[0]\n",
    "    \n",
    "    # PubMed Link\n",
    "    pubmed_link = 'https://www.ncbi.nlm.nih.gov/pubmed/' + master_id_list[i] + '?'\n",
    "    # assign value to the dataframe\n",
    "    data.at[i, ['Title', 'All Authors', 'Abstract', 'Journal', 'Publication Type', 'Publication Year', \n",
    "                'Full Citation', 'PubMed Link']] = [title, authors, abstract, journal, publication_type, publication_year, full_cit, pubmed_link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "literature_grid = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>All Authors</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Publication Type</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Full Citation</th>\n",
       "      <th>PubMed Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>An outbreak of severe acute respiratory syndro...</td>\n",
       "      <td>Engineering (Beijing)</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>2020</td>\n",
       "      <td>Engineering (Beijing). 2020 Mar 18. [Epub ahea...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32346491?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32341630</td>\n",
       "      <td>Tackling Corona Virus Disease 2019 (COVID 19) ...</td>\n",
       "      <td>Ramesh, Naveen; Siddaiah, Archana; Joseph, Bobby</td>\n",
       "      <td>Coronaviruses are zoonotic viruses and six spe...</td>\n",
       "      <td>Indian J Occup Environ Med</td>\n",
       "      <td>Journal Article\\nReview</td>\n",
       "      <td>2020</td>\n",
       "      <td>Indian J Occup Environ Med. 2020 Jan-Apr;24(1)...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32341630?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>32339137</td>\n",
       "      <td>Mental health and a novel coronavirus (2019-nC...</td>\n",
       "      <td>Zheng, Wei</td>\n",
       "      <td></td>\n",
       "      <td>J Affect Disord</td>\n",
       "      <td>Letter</td>\n",
       "      <td>2020</td>\n",
       "      <td>J Affect Disord. 2020 May 15;269:201-202.</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32339137?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>32337113</td>\n",
       "      <td>Brief Review on COVID-19: The 2020 Pandemic Ca...</td>\n",
       "      <td>Valencia, Damian N</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus ...</td>\n",
       "      <td>Cureus</td>\n",
       "      <td>Journal Article\\nReview</td>\n",
       "      <td>2020</td>\n",
       "      <td>Cureus. 2020 Mar 24;12(3):e7386.</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32337113?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32336558</td>\n",
       "      <td>CRT 2020, COVID-19 and beyond.</td>\n",
       "      <td>Waksman, Ron</td>\n",
       "      <td></td>\n",
       "      <td>Cardiovasc Revasc Med</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>2020</td>\n",
       "      <td>Cardiovasc Revasc Med. 2020 Mar 19. [Epub ahea...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32336558?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              Title  \\\n",
       "0  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "1  32341630  Tackling Corona Virus Disease 2019 (COVID 19) ...   \n",
       "2  32339137  Mental health and a novel coronavirus (2019-nC...   \n",
       "3  32337113  Brief Review on COVID-19: The 2020 Pandemic Ca...   \n",
       "4  32336558                     CRT 2020, COVID-19 and beyond.   \n",
       "\n",
       "                                         All Authors  \\\n",
       "0  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "1   Ramesh, Naveen; Siddaiah, Archana; Joseph, Bobby   \n",
       "2                                         Zheng, Wei   \n",
       "3                                 Valencia, Damian N   \n",
       "4                                       Waksman, Ron   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  An outbreak of severe acute respiratory syndro...   \n",
       "1  Coronaviruses are zoonotic viruses and six spe...   \n",
       "2                                                      \n",
       "3  Severe acute respiratory syndrome coronavirus ...   \n",
       "4                                                      \n",
       "\n",
       "                      Journal         Publication Type Publication Year  \\\n",
       "0       Engineering (Beijing)          Journal Article             2020   \n",
       "1  Indian J Occup Environ Med  Journal Article\\nReview             2020   \n",
       "2             J Affect Disord                   Letter             2020   \n",
       "3                      Cureus  Journal Article\\nReview             2020   \n",
       "4       Cardiovasc Revasc Med          Journal Article             2020   \n",
       "\n",
       "                                       Full Citation  \\\n",
       "0  Engineering (Beijing). 2020 Mar 18. [Epub ahea...   \n",
       "1  Indian J Occup Environ Med. 2020 Jan-Apr;24(1)...   \n",
       "2          J Affect Disord. 2020 May 15;269:201-202.   \n",
       "3                   Cureus. 2020 Mar 24;12(3):e7386.   \n",
       "4  Cardiovasc Revasc Med. 2020 Mar 19. [Epub ahea...   \n",
       "\n",
       "                                     PubMed Link  \n",
       "0  https://www.ncbi.nlm.nih.gov/pubmed/32346491?  \n",
       "1  https://www.ncbi.nlm.nih.gov/pubmed/32341630?  \n",
       "2  https://www.ncbi.nlm.nih.gov/pubmed/32339137?  \n",
       "3  https://www.ncbi.nlm.nih.gov/pubmed/32337113?  \n",
       "4  https://www.ncbi.nlm.nih.gov/pubmed/32336558?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literature_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns = ['PMID', 'Title', 'All Authors', 'Sentence', 'Keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(text):\n",
    "    clean_up_list = ['RESEARCH',  'AND', 'PURPOSE: ', 'METHODS: ', 'METHOD:', 'RESULTS: ', 'CONCLUSIONS: ',\n",
    "                     'INTERPRETATION: ', 'OBJECTIVES:', 'RATIONALE: ', 'RECENT FINDINGS: '\n",
    "                     'OBJECTIVE', 'RESULTS', 'INTRODUCTION', 'RECENT FINDING', 'SUMMARY: '\n",
    "                     'METHODS', 'CONCLUSIONS', '\\n', 'BACKGROUND','Purpose:', 'PURPOSE: ','PURPOSE',\n",
    "                     'Methods:', 'Conclusion:', 'Background:','Results:', 'DESIGN']\n",
    "    for stopwords in clean_up_list:\n",
    "        text = str(text).replace(stopwords, '')\n",
    "    try:\n",
    "        index = text.index('.')\n",
    "        if index<len(text)-1:\n",
    "            if text[index+1].isupper():\n",
    "                text = text[:index] + '. ' + text[index+1:]\n",
    "        else:\n",
    "            pass\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return text\n",
    "\n",
    "def sent_tokenize(text):\n",
    "    sentence_list = text.split('. ')\n",
    "    sentence_list_temp = []\n",
    "    for sentence in sentence_list:\n",
    "        if len(sentence)>1:\n",
    "            if sentence[-1] == '.':\n",
    "                sentence_list_temp.append(sentence)\n",
    "            else:\n",
    "                sentence_list_temp.append(sentence+'.')\n",
    "    return sentence_list_temp\n",
    "\n",
    "def first_term_all_cap(sentence):\n",
    "    all_cap = True\n",
    "    for char in sentence.split(' ')[0]:\n",
    "        if not char.isupper():\n",
    "            all_cap = False\n",
    "            break\n",
    "    return all_cap\n",
    "\n",
    "def first_char_cap(sentence):\n",
    "    first_char_cap = True\n",
    "    for term in sentence.split(' '):\n",
    "        if not term[0].isupper():\n",
    "            first_char_cap = False\n",
    "            break\n",
    "    return first_char_cap\n",
    "\n",
    "def all_cap(sentence):\n",
    "    all_cap = True\n",
    "    for term in sentence.split(' '):\n",
    "        for char in term:\n",
    "            if not char.isupper():\n",
    "                all_cap = False\n",
    "                break\n",
    "    return all_cap\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    while sentence[0] == ' ':\n",
    "        sentence = sentence[1:]\n",
    "    sentence = sentence.replace('  ', '')\n",
    "    term_list = sentence.split(' ')\n",
    "    if not all_cap(sentence):\n",
    "        if first_char_cap(sentence):\n",
    "            term_list_after = []\n",
    "            for term in term_list:\n",
    "                if all_cap(term):\n",
    "                    term_list_after.append(term)\n",
    "                else:\n",
    "                    term_list_after.append(term[0].lower()+term[1:])    \n",
    "            sentence = ' '.join(term_list_after) \n",
    "        else:\n",
    "            term_list_after = []\n",
    "            for term in term_list:\n",
    "                if all_cap(term.replace(':','')):\n",
    "                    term_list_after.append(term)\n",
    "                else:\n",
    "                    term_list_after.append(term[0].lower()+term[1:])    \n",
    "            sentence = ' '.join(term_list_after)  \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 648/648 [00:04<00:00, 151.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(literature_grid))):\n",
    "    data_temp = pd.DataFrame(columns = ['PMID', 'Title', 'All Authors', 'Sentence', 'Keywords', 'Key Terms'])\n",
    "    if str(literature_grid.iloc[i]['Abstract']) == '':\n",
    "        text = clean_up(str(literature_grid.iloc[i]['Title']))\n",
    "    else:\n",
    "        text = clean_up(str(literature_grid.iloc[i]['Title']) + ' ' + str(literature_grid.iloc[i]['Abstract']))\n",
    "    sent_text = sent_tokenize(text)\n",
    "    data_temp['Sentence'] = sent_text\n",
    "    data_temp['PMID'] = literature_grid['PMID'][i]\n",
    "    data_temp['Title'] = literature_grid['Title'][i]\n",
    "    data_temp['All Authors'] = literature_grid['All Authors'][i]\n",
    "    data = data.append(data_temp,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1\\\n",
    "    import Features, SentimentOptions, KeywordsOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nYmrbPnNeBRnBullFI6KBqqJsrY9jCNvv1Dv0QBuuSQY #apothecom.NLP\n",
    "# 2H5wZ6Ghn2VBsAUUcfKOsJVIQz1zX3biAj8S9ozMlLZX\n",
    "authenticator = IAMAuthenticator('nYmrbPnNeBRnBullFI6KBqqJsrY9jCNvv1Dv0QBuuSQY')\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2019-07-12',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "natural_language_understanding.set_service_url('https://gateway.watsonplatform.net/natural-language-understanding/api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2759 sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>All Authors</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Key Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>An outbreak of severe acute respiratory syndro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>More than 16% of patients developed acute resp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>No specific treatment has been reported.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>Herein, we examine the effects of Favipiravir ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>Patients with laboratory-confirmed COVID-19 wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>Changes in chest computed tomography (CT), vir...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>For the 35 patients enrolled in the FPV arm an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>A shorter viral clearance time was found for t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>The FPV arm also showed significant improvemen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              Title  \\\n",
       "0  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "1  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "2  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "3  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "4  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "5  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "6  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "7  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "8  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "9  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "\n",
       "                                         All Authors  \\\n",
       "0  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "1  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "2  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "3  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "4  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "5  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "6  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "7  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "8  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "9  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "\n",
       "                                            Sentence Keywords Key Terms  \n",
       "0  Experimental Treatment with Favipiravir for CO...      NaN       NaN  \n",
       "1  An outbreak of severe acute respiratory syndro...      NaN       NaN  \n",
       "2  More than 16% of patients developed acute resp...      NaN       NaN  \n",
       "3           No specific treatment has been reported.      NaN       NaN  \n",
       "4  Herein, we examine the effects of Favipiravir ...      NaN       NaN  \n",
       "5  Patients with laboratory-confirmed COVID-19 wh...      NaN       NaN  \n",
       "6  Changes in chest computed tomography (CT), vir...      NaN       NaN  \n",
       "7  For the 35 patients enrolled in the FPV arm an...      NaN       NaN  \n",
       "8  A shorter viral clearance time was found for t...      NaN       NaN  \n",
       "9  The FPV arm also showed significant improvemen...      NaN       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "print('There are', len(data), 'sentences')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 557/2759 [07:25<31:28,  1.17it/s]  ERROR:root:Error in service call\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\", line 1336, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\", line 306, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\", line 267, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\", line 312, in recv_into\n",
      "    return self.recv_into(*args, **kwargs)\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\", line 310, in recv_into\n",
      "    raise timeout('The read operation timed out')\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\", line 368, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\", line 686, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 306, in _raise_timeout\n",
      "    raise ReadTimeoutError(self, url, \"Read timed out. (read timeout=%s)\" % timeout_value)\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='gateway.watsonplatform.net', port=443): Read timed out. (read timeout=60)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 208, in send\n",
      "    response = requests.request(**request, cookies=self.jar, **kwargs)\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 529, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='gateway.watsonplatform.net', port=443): Read timed out. (read timeout=60)\n",
      " 35%|███▌      | 966/2759 [13:44<19:12,  1.56it/s]   ERROR:root:unsupported text language: pl\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: pl, Code: 400 , X-global-transaction-id: a62bc6f7b92e8c0a583c3b85cc6d8b81\n",
      " 35%|███▌      | 968/2759 [13:45<18:56,  1.58it/s]ERROR:root:unsupported text language: cubulco achi\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: cubulco achi, Code: 400 , X-global-transaction-id: 724ddb01fc2f645a22686af5d6173e2d\n",
      " 35%|███▌      | 970/2759 [13:46<18:12,  1.64it/s]ERROR:root:unsupported text language: pl\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: pl, Code: 400 , X-global-transaction-id: 4055d467de2b26f064c066753c7e5b96\n",
      " 35%|███▌      | 974/2759 [13:49<17:55,  1.66it/s]ERROR:root:unsupported text language: sr\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: sr, Code: 400 , X-global-transaction-id: 426a41726b9703739fe5b84934bb7b3c\n",
      " 35%|███▌      | 976/2759 [13:50<18:31,  1.60it/s]ERROR:root:unsupported text language: pl\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: pl, Code: 400 , X-global-transaction-id: fa04c7c05048856e94370f0f01519322\n",
      " 36%|███▌      | 980/2759 [13:53<21:22,  1.39it/s]ERROR:root:unsupported text language: sr\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: sr, Code: 400 , X-global-transaction-id: 675d22cdf52ef9b19db66dd820cb8ea8\n",
      " 36%|███▌      | 981/2759 [13:54<20:46,  1.43it/s]ERROR:root:unsupported text language: ro\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: ro, Code: 400 , X-global-transaction-id: 2fd49a189745a948bf5e369765f4b817\n",
      " 36%|███▌      | 982/2759 [13:54<19:36,  1.51it/s]ERROR:root:unsupported text language: ro\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: ro, Code: 400 , X-global-transaction-id: 7163fbf5e2a73d1b9007565cb9c72403\n",
      " 36%|███▌      | 985/2759 [13:56<18:32,  1.60it/s]ERROR:root:unsupported text language: pl\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: pl, Code: 400 , X-global-transaction-id: bbcb618c97ab2eac0a254bf8d57d8192\n",
      " 36%|███▌      | 991/2759 [14:00<18:51,  1.56it/s]ERROR:root:unsupported text language: cubulco achi\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: cubulco achi, Code: 400 , X-global-transaction-id: 29882e4cf5998135b320c8fd6f82207c\n",
      " 41%|████      | 1135/2759 [15:35<16:26,  1.65it/s]ERROR:root:unsupported text language: no\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: no, Code: 400 , X-global-transaction-id: 000fa2e0edefed7d522aa034f76730a9\n",
      " 53%|█████▎    | 1458/2759 [19:07<15:04,  1.44it/s]ERROR:root:unsupported text language: ca\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: ca, Code: 400 , X-global-transaction-id: 482d8977ebfcdf6399dea5779b780f1a\n",
      " 65%|██████▍   | 1785/2759 [22:45<10:22,  1.56it/s]ERROR:root:unsupported text language: unknown\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: unknown, Code: 400 , X-global-transaction-id: 0b6fa91419c86c94a92ad6b15b0703fc\n",
      " 68%|██████▊   | 1870/2759 [23:43<09:50,  1.51it/s]ERROR:root:unsupported text language: unknown\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ehu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: unknown, Code: 400 , X-global-transaction-id: fa3ebee54d5f5231903088567c1bad02\n",
      "100%|██████████| 2759/2759 [35:28<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(data))):\n",
    "    text = clean_up_sentence(data.iloc[i]['Sentence'])\n",
    "    try:\n",
    "        if len(text) > 20:\n",
    "            response = natural_language_understanding.analyze(\n",
    "                      text=text,\n",
    "                      features=Features(keywords=KeywordsOptions())).get_result()\n",
    "            keywords = '||'.join([keyword['text'] for keyword in response['keywords']])\n",
    "            term_list = []\n",
    "            for kt in [keyword['text'] for keyword in response['keywords']]:\n",
    "                kt_list = kt.split(' ')\n",
    "                term_list = term_list + kt_list\n",
    "            terms = '||'.join(term_list)\n",
    "            data.at[i,['Keywords', 'Key Terms']] = keywords, terms\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>All Authors</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Key Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>experimental treatment||open-Label control stu...</td>\n",
       "      <td>experimental||treatment||open-Label||control||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>An outbreak of severe acute respiratory syndro...</td>\n",
       "      <td>SARS-CoV-2||coronavirus disease||infection||ou...</td>\n",
       "      <td>SARS-CoV-2||coronavirus||disease||infection||o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>More than 16% of patients developed acute resp...</td>\n",
       "      <td>acute respiratory distress syndrome||patients|...</td>\n",
       "      <td>acute||respiratory||distress||syndrome||patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>No specific treatment has been reported.</td>\n",
       "      <td>specific treatment</td>\n",
       "      <td>specific||treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32346491</td>\n",
       "      <td>Experimental Treatment with Favipiravir for CO...</td>\n",
       "      <td>Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...</td>\n",
       "      <td>Herein, we examine the effects of Favipiravir ...</td>\n",
       "      <td>effects of favipiravir||FPV||treatment of cOVI...</td>\n",
       "      <td>effects||of||favipiravir||FPV||treatment||of||...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              Title  \\\n",
       "0  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "1  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "2  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "3  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "4  32346491  Experimental Treatment with Favipiravir for CO...   \n",
       "\n",
       "                                         All Authors  \\\n",
       "0  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "1  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "2  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "3  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "4  Cai, Qingxian; Yang, Minghui; Liu, Dongjing; C...   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  Experimental Treatment with Favipiravir for CO...   \n",
       "1  An outbreak of severe acute respiratory syndro...   \n",
       "2  More than 16% of patients developed acute resp...   \n",
       "3           No specific treatment has been reported.   \n",
       "4  Herein, we examine the effects of Favipiravir ...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  experimental treatment||open-Label control stu...   \n",
       "1  SARS-CoV-2||coronavirus disease||infection||ou...   \n",
       "2  acute respiratory distress syndrome||patients|...   \n",
       "3                                 specific treatment   \n",
       "4  effects of favipiravir||FPV||treatment of cOVI...   \n",
       "\n",
       "                                           Key Terms  \n",
       "0  experimental||treatment||open-Label||control||...  \n",
       "1  SARS-CoV-2||coronavirus||disease||infection||o...  \n",
       "2  acute||respiratory||distress||syndrome||patien...  \n",
       "3                                specific||treatment  \n",
       "4  effects||of||favipiravir||FPV||treatment||of||...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_term_frequency = {}\n",
    "for i in range(len(data)):\n",
    "    for key_term in str(data['Key Terms'][i]).split('||'):\n",
    "        if key_term in key_term_frequency:\n",
    "            key_term_frequency[key_term] += 1\n",
    "        else:\n",
    "            key_term_frequency[key_term] = 1\n",
    "            \n",
    "key_term_frequency_df = pd.DataFrame(key_term_frequency, index=[1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_frequency = {}\n",
    "for i in range(len(data)):\n",
    "    for keyword in str(data['Keywords'][i]).split('||'):\n",
    "        if keyword in keyword_frequency:\n",
    "            keyword_frequency[keyword] += 1\n",
    "        else:\n",
    "            keyword_frequency[keyword] = 1\n",
    "            \n",
    "keyword_frequency_df = pd.DataFrame(keyword_frequency, index=[1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(r'C:\\Users\\ehu\\repos\\dna\\NLP Projects\\COVID NLP.xlsx', engine='xlsxwriter')\n",
    "data.to_excel(writer, sheet_name='Grid', index=False)\n",
    "keyword_frequency_df.to_excel(writer, sheet_name='Keywords')\n",
    "key_term_frequency_df.to_excel(writer, sheet_name='Key terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()# Finished - save\n",
    "writer.close()# Finished - close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
